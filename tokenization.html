<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tokenization &amp; Vocabulary Visualizer</title>
    <link rel="stylesheet" href="style.css" />
    <style>
      /* Additional local styles for the tokenization controls */
      #controls {
        display: flex;
        flex-direction: column;
        gap: 0.5rem;
        margin-bottom: 1rem;
      }
      #controls textarea {
        width: 100%;
        height: 120px;
        font-family: monospace;
        padding: 0.5rem;
        resize: vertical;
        background: #1d2340;
        color: #e6e6e6;
        border: 1px solid #3a3f6b;
        border-radius: 4px;
      }
      #controls button {
        padding: 0.5rem 1rem;
        font-size: 1rem;
        border: none;
        border-radius: 6px;
        background: #525893;
        color: white;
        cursor: pointer;
        transition: background 0.25s;
      }
      #controls button:hover {
        background: #6c74b9;
      }
    </style>
  </head>
  <body>
    <header>
      <h1>Tokenization &amp; Vocabulary</h1>
      <p>
        See how raw text is split into tokens, how a vocabulary is built, and
        how lemmatization and stop‑word removal affect the representation. Use
        the buttons below to tokenize the text, convert surface forms to their
        lemmas, and remove common stop words. Tokens appear as coloured
        bubbles on the canvas.
      </p>
    </header>
    <main>
      <div id="controls">
        <textarea id="inputText"
          >The quick brown fox jumps over the lazy dog. Bob’s bike is running
          fast.</textarea
        >
        <button id="tokenizeBtn">Tokenize</button>
        <button id="lemmatizeBtn">Apply Lemmatization</button>
        <button id="stopwordBtn">Remove Stop Words</button>
      </div>
      <div id="canvasContainer" style="display: flex; justify-content: center"></div>
      <p id="vocabInfo"></p>
    </main>
    <footer>
      <p>
        Tokenization chops text into tokens and throws away punctuation. Stop
        words are common terms removed from the vocabulary, and lemmatization
        maps morphological variants to a single root. Try writing your own
        sentence to see how the vocabulary evolves.
      </p>
      <p><a href="index.html">Back to menu</a></p>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/p5@1.9.0/lib/p5.min.js"></script>
    <script src="tokenization.js"></script>
  </body>
</html>