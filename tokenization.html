<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tokenization &amp; Vocabulary Visualizer</title>
    <link rel="stylesheet" href="style.css" />
    <style>
      /* Additional local styles for controls */
      #controls {
        display: flex;
        flex-direction: column;
        gap: 0.5rem;
        margin-bottom: 1rem;
      }
      #controls textarea {
        width: 100%;
        height: 120px;
        font-family: monospace;
        padding: 0.5rem;
        resize: vertical;
        background: #1d2340;
        color: #e6e6e6;
        border: 1px solid #3a3f6b;
        border-radius: 4px;
      }
      #controls button {
        padding: 0.5rem 1rem;
        font-size: 1rem;
        border: none;
        border-radius: 6px;
        background: #525893;
        color: white;
        cursor: pointer;
        transition: background 0.25s;
      }
      #controls button:hover {
        background: #6c74b9;
      }
      canvas {
        border: 1px solid #3a3f6b;
      }
    </style>
  </head>
  <body>
    <header>
      <h1>Tokenization &amp; Vocabulary</h1>
      <p>
        See how raw text is split into tokens, how a vocabulary is built,
        and how lemmatization and stop‑word removal affect the representation.
      </p>
    </header>
    <main style="flex-direction: column; align-items: stretch;">
      <div id="controls">
        <textarea id="inputText">The quick brown fox jumps over the lazy dog. Bob’s bike is running fast.</textarea>
        <button id="tokenizeBtn">Tokenize</button>
        <button id="lemmatizeBtn">Apply Lemmatization</button>
        <button id="stopwordBtn">Remove Stop Words</button>
      </div>
      <div id="canvasContainer" style="display:flex; justify-content:center;"></div>
      <p id="vocabInfo"></p>
    </main>
    <footer>
      <p>
        Tokenization chops text into tokens and throws away punctuation【509690558521721†L7-L16】. Stop words are common terms removed
        from the vocabulary【161262644849266†L12-L19】, and lemmatization maps morphological
        variants to a single root【86036143564499†L123-L128】.
      </p>
      <p><a href="index.html">Back to menu</a></p>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/p5@1.9.0/lib/p5.min.js"></script>
    <script src="tokenization.js"></script>
  </body>
</html>